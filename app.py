# -*- coding: utf-8 -*-
"""App.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aJfl2DkUsg5xgDtMpG3uDpniTJbDnmCg
"""

from flask import Flask, request, jsonify
import re
import nltk
import pandas as pd
import numpy as np
import pickle
from collections import OrderedDict
from nltk.corpus import stopwords
from nltk import WordNetLemmatizer
from nltk.stem import SnowballStemmer
from nltk.tokenize import word_tokenize
import tensorflow as tf
from keras.preprocessing.sequence import pad_sequences
from keras.models import load_model
from keras.backend import set_session
import pandas as pd
from keras.models import Sequential
from keras.layers import Dense, Embedding, Flatten, Dropout
from keras.layers.pooling import MaxPooling1D
from keras.layers.convolutional import Conv1D
from keras.regularizers import l2
from keras.callbacks import EarlyStopping
import gensim
from gensim.models import Word2Vec
from keras.preprocessing.sequence import pad_sequences
from keras.models import load_model
import numpy as np
import keras
import os
from gensim.test.utils import get_tmpfile
from gensim.models import KeyedVectors
from gensim.corpora import Dictionary
import pickle
stop = stopwords.words('english')
lemmatizer = WordNetLemmatizer()
stemmer = SnowballStemmer('english')

app = Flask(__name__)

def token_to_index(token, dictionary):
    """
    Given a token and a gensim dictionary, return the token index
    if in the dictionary, None otherwise.
    Reserve index 0 for padding.
    """
    if token not in dictionary.token2id:
        return None
    return dictionary.token2id[token] + 1

def texts_to_indices(text, dictionary):
    """
    Given a list of tokens (text) and a gensim dictionary, return a list
    of token ids.
    """
    result = list(map(lambda x: token_to_index(x, dictionary), text))
    return list(filter(None, result))


def remove_stop_lemmatize(text):
    text = ' '.join([word for word in text.split()
                      if word not in stop])
    text = ' '.join([stemmer.stem(word) for word in text.split()])
    return text
def normalize(file_str):
    # 1) remove numbers and spacial characters
    file_str = re.sub(r'([^a-zA-Z\s]+?)', '', file_str).replace("\n",' ')
    # 2) Lower case
    file_str = file_str.lower()
    return file_str

def predict_op(test_input):
  MAX_SEQUENCE_LENGTH = 126
  test_texts_indices =  texts_to_indices(test_input, corpus_dict)
  x_data = pad_sequences([test_texts_indices], maxlen=MAX_SEQUENCE_LENGTH)
  pred_prob = model.predict(x_data)
  pred_dict = dict(zip(label_names, list(pred_prob[0])))
  return pred_dict


def load():
    global model, corpus_dict,label_arr,label_names
    model = load_model('src/models/stackoverflow_model_emb.model')
    corpus_dict = Dictionary.load('src/models/stackoverflow_questions.dict')
    labels_arr = pd.read_csv("src/data/Labels.csv")
    label_names = labels_arr.columns.tolist()
    global graph
    graph = tf.get_default_graph()

# request model prediction
@app.route('/', methods=['GET', 'POST'])
def predict():
    if request.method == 'GET':
        a = request.args.get('query')
    if request.method == 'POST':
        a = request.form.get('query')
    processed_text = normalize(remove_stop_lemmatize(a))
    with graph.as_default():
      output = predict_op
    return output
# start Flask server
if __name__ == '__main__':
    print('Loading model...')
    load()
    app.run(debug=False)